{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWU28v9QVX67MuDuPgAiq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinilsukumar/Data-analysis-ML-Projects/blob/main/AlexNet_CNN_replicate_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hAyotJhebDeB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            # Define feature extractor here...\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32,64, kernel_size=3 ,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=1)\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            # Define classifier here...\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(32*12*12,2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048,1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024,num)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define forward network 'x' that combines feature extractor and classifier\n",
        "        x = self.feature(x)\n",
        "        x = x.view(-1,32*12*12)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "md6-S9Xxb1UL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subset(full_train_set, full_test_set, label_one, label_two):\n",
        "    # Sample the correct train labels\n",
        "    train_set = []\n",
        "    data_lim = 20000\n",
        "    for data in full_train_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                train_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    test_set = []\n",
        "    data_lim = 1000\n",
        "    for data in full_test_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                test_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "1iq1bHixb91Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,train_loader,epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "ZMh_7wvMcB3i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()#size_average=False\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc=100. * float(correct.to(torch.device('cpu')).numpy())\n",
        "    test_accuracy = (acc / len(test_loader.dataset))\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "29fp6BbAcGyw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_one = 1\n",
        "input_data_two = 2\n",
        "epochs = 2\n",
        "label_one = input_data_one\n",
        "label_two = input_data_two\n",
        "\"\"\"  Call to function that will perform the computation. \"\"\"\n",
        "if label_one!=label_two and 0<=label_one<=9 and 0<=label_two<=9:\n",
        "  torch.manual_seed(42)\n",
        "  # Load MNIST dataset\n",
        "  trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "  full_train_set = dset.MNIST(root='./data', train=True, transform=trans, download=True)\n",
        "  full_test_set = dset.MNIST(root='./data', train=False, transform=trans)\n",
        "  batch_size = 16\n",
        "  # Get final train and test sets\n",
        "  train_set, test_set = load_subset(full_train_set,full_test_set,label_one,label_two)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=False)\n",
        "  test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "  model = AlexNet()\n",
        "  if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "    train(model,optimizer,train_loader,epoch)\n",
        "    accuracy = test(model,test_loader)\n",
        "\n",
        "    print(round(accuracy,2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_qTo6lScHhK",
        "outputId": "d63a07ac-ca05-4cc4-a762-d51b3a1bfaef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67.36\n",
            "78.1\n"
          ]
        }
      ]
    }
  ]
}